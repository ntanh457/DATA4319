{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>gmat</th><th>gpa</th><th>work_experience</th><th>admitted</th></tr><tr><th></th><th>Int64</th><th>Float64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>40 rows × 4 columns</p><tr><th>1</th><td>780</td><td>4.0</td><td>3</td><td>1</td></tr><tr><th>2</th><td>750</td><td>3.9</td><td>4</td><td>1</td></tr><tr><th>3</th><td>690</td><td>3.3</td><td>3</td><td>0</td></tr><tr><th>4</th><td>710</td><td>3.7</td><td>5</td><td>1</td></tr><tr><th>5</th><td>680</td><td>3.9</td><td>4</td><td>0</td></tr><tr><th>6</th><td>730</td><td>3.7</td><td>6</td><td>1</td></tr><tr><th>7</th><td>690</td><td>2.3</td><td>1</td><td>0</td></tr><tr><th>8</th><td>720</td><td>3.3</td><td>4</td><td>1</td></tr><tr><th>9</th><td>740</td><td>3.3</td><td>5</td><td>1</td></tr><tr><th>10</th><td>690</td><td>1.7</td><td>1</td><td>0</td></tr><tr><th>11</th><td>610</td><td>2.7</td><td>3</td><td>0</td></tr><tr><th>12</th><td>690</td><td>3.7</td><td>5</td><td>1</td></tr><tr><th>13</th><td>710</td><td>3.7</td><td>6</td><td>1</td></tr><tr><th>14</th><td>680</td><td>3.3</td><td>4</td><td>0</td></tr><tr><th>15</th><td>770</td><td>3.3</td><td>3</td><td>1</td></tr><tr><th>16</th><td>610</td><td>3.0</td><td>1</td><td>0</td></tr><tr><th>17</th><td>580</td><td>2.7</td><td>4</td><td>0</td></tr><tr><th>18</th><td>650</td><td>3.7</td><td>6</td><td>1</td></tr><tr><th>19</th><td>540</td><td>2.7</td><td>2</td><td>0</td></tr><tr><th>20</th><td>590</td><td>2.3</td><td>3</td><td>0</td></tr><tr><th>21</th><td>620</td><td>3.3</td><td>2</td><td>1</td></tr><tr><th>22</th><td>600</td><td>2.0</td><td>1</td><td>0</td></tr><tr><th>23</th><td>550</td><td>2.3</td><td>4</td><td>0</td></tr><tr><th>24</th><td>550</td><td>2.7</td><td>1</td><td>0</td></tr><tr><th>25</th><td>570</td><td>3.0</td><td>2</td><td>0</td></tr><tr><th>26</th><td>670</td><td>3.3</td><td>6</td><td>1</td></tr><tr><th>27</th><td>660</td><td>3.7</td><td>4</td><td>1</td></tr><tr><th>28</th><td>580</td><td>2.3</td><td>2</td><td>0</td></tr><tr><th>29</th><td>650</td><td>3.7</td><td>6</td><td>1</td></tr><tr><th>30</th><td>660</td><td>3.3</td><td>5</td><td>1</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& gmat & gpa & work\\_experience & admitted\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 780 & 4.0 & 3 & 1 \\\\\n",
       "\t2 & 750 & 3.9 & 4 & 1 \\\\\n",
       "\t3 & 690 & 3.3 & 3 & 0 \\\\\n",
       "\t4 & 710 & 3.7 & 5 & 1 \\\\\n",
       "\t5 & 680 & 3.9 & 4 & 0 \\\\\n",
       "\t6 & 730 & 3.7 & 6 & 1 \\\\\n",
       "\t7 & 690 & 2.3 & 1 & 0 \\\\\n",
       "\t8 & 720 & 3.3 & 4 & 1 \\\\\n",
       "\t9 & 740 & 3.3 & 5 & 1 \\\\\n",
       "\t10 & 690 & 1.7 & 1 & 0 \\\\\n",
       "\t11 & 610 & 2.7 & 3 & 0 \\\\\n",
       "\t12 & 690 & 3.7 & 5 & 1 \\\\\n",
       "\t13 & 710 & 3.7 & 6 & 1 \\\\\n",
       "\t14 & 680 & 3.3 & 4 & 0 \\\\\n",
       "\t15 & 770 & 3.3 & 3 & 1 \\\\\n",
       "\t16 & 610 & 3.0 & 1 & 0 \\\\\n",
       "\t17 & 580 & 2.7 & 4 & 0 \\\\\n",
       "\t18 & 650 & 3.7 & 6 & 1 \\\\\n",
       "\t19 & 540 & 2.7 & 2 & 0 \\\\\n",
       "\t20 & 590 & 2.3 & 3 & 0 \\\\\n",
       "\t21 & 620 & 3.3 & 2 & 1 \\\\\n",
       "\t22 & 600 & 2.0 & 1 & 0 \\\\\n",
       "\t23 & 550 & 2.3 & 4 & 0 \\\\\n",
       "\t24 & 550 & 2.7 & 1 & 0 \\\\\n",
       "\t25 & 570 & 3.0 & 2 & 0 \\\\\n",
       "\t26 & 670 & 3.3 & 6 & 1 \\\\\n",
       "\t27 & 660 & 3.7 & 4 & 1 \\\\\n",
       "\t28 & 580 & 2.3 & 2 & 0 \\\\\n",
       "\t29 & 650 & 3.7 & 6 & 1 \\\\\n",
       "\t30 & 660 & 3.3 & 5 & 1 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "40×4 DataFrame\n",
       "│ Row │ gmat  │ gpa     │ work_experience │ admitted │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mInt64\u001b[39m           │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼───────┼─────────┼─────────────────┼──────────┤\n",
       "│ 1   │ 780   │ 4.0     │ 3               │ 1        │\n",
       "│ 2   │ 750   │ 3.9     │ 4               │ 1        │\n",
       "│ 3   │ 690   │ 3.3     │ 3               │ 0        │\n",
       "│ 4   │ 710   │ 3.7     │ 5               │ 1        │\n",
       "│ 5   │ 680   │ 3.9     │ 4               │ 0        │\n",
       "│ 6   │ 730   │ 3.7     │ 6               │ 1        │\n",
       "│ 7   │ 690   │ 2.3     │ 1               │ 0        │\n",
       "│ 8   │ 720   │ 3.3     │ 4               │ 1        │\n",
       "│ 9   │ 740   │ 3.3     │ 5               │ 1        │\n",
       "│ 10  │ 690   │ 1.7     │ 1               │ 0        │\n",
       "⋮\n",
       "│ 30  │ 660   │ 3.3     │ 5               │ 1        │\n",
       "│ 31  │ 640   │ 3.0     │ 1               │ 0        │\n",
       "│ 32  │ 620   │ 2.7     │ 2               │ 0        │\n",
       "│ 33  │ 660   │ 4.0     │ 4               │ 1        │\n",
       "│ 34  │ 660   │ 3.3     │ 6               │ 1        │\n",
       "│ 35  │ 680   │ 3.3     │ 5               │ 1        │\n",
       "│ 36  │ 650   │ 2.3     │ 1               │ 0        │\n",
       "│ 37  │ 670   │ 2.7     │ 2               │ 0        │\n",
       "│ 38  │ 580   │ 3.3     │ 1               │ 0        │\n",
       "│ 39  │ 590   │ 1.7     │ 4               │ 0        │\n",
       "│ 40  │ 690   │ 3.7     │ 5               │ 1        │"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV\n",
    "data= CSV.read(\"candidates_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40-element Array{Int64,1}:\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " ⋮\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data=[[x[1],x[2]] for x in zip(data.gmat,data.gpa)]\n",
    "y_data=[x for x in data.admitted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_cost (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ(x) = 1/(1+exp(-x))\n",
    "\n",
    "function cross_entropy_loss(x,y,w,b)\n",
    "    return -y*log(σ(w'x + b)) - (1-y)*log(1-σ(w'x+b))\n",
    "end \n",
    "\n",
    "function average_cost(features, labels, w, b)\n",
    "    N = length(features)\n",
    "    return (1/N)*sum([cross_entropy_loss(features[i], labels[i],w,b) for i = 1:N])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch_gradient_descent(features,labels,w,b,α)\n",
    "    del_w = [0.0 for i = 1:length(w)]\n",
    "    del_b = 0.0\n",
    "    N = length(features)\n",
    "    for i = 1:N\n",
    "        del_w += (σ(w'features[i] + b) - labels[i])*features[i]\n",
    "        del_b += (σ(w'features[i] + b) - labels[i])\n",
    "    end\n",
    "    w = w - α*del_w\n",
    "    b = b - α*del_b\n",
    "    return w,b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.012, 0.0006000000000000002], -0.0001)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b = batch_gradient_descent(x_data, y_data, [0.0,0.0], 0.0, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_batch_gradient_descent(features,labels, w,b,α, epochs)\n",
    "    for i = 1:epochs \n",
    "        \n",
    "        w, b = batch_gradient_descent(features, labels, w,b,α)\n",
    "        if i == 1\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        if i == epochs/10\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        if i == epochs/8\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        if i == epochs/4\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        if i == epochs/2\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        if i == epochs\n",
    "            println(\"Epochs \", i , \" with loss \", average_cost(x_data, y_data,w,b))\n",
    "        end\n",
    "        end \n",
    "    return w,b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1 with loss 0.6931188566349795\n",
      "Epochs 100000 with loss 0.6855799117618873\n",
      "Epochs 125000 with loss 0.6837589079497152\n",
      "Epochs 250000 with loss 0.6749998518952888\n",
      "Epochs 500000 with loss 0.6590868605720882\n",
      "Epochs 1000000 with loss 0.6326918737673819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.0020551903863979, 0.47622113690915635], -0.11626329950708125)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [0.0,0.0]\n",
    "b = 0.0\n",
    "\n",
    "w,b = train_batch_gradient_descent(x_data,y_data, w,b,0.0000001,1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(x,y,w,b)\n",
    "    if σ(w'x+b) >= 0.5\n",
    "        println(\"predict accepted\")\n",
    "        y==1 ? println(\"was accepted\") : println(\"was not accepted\")\n",
    "    else\n",
    "        println(\"predict not accepted\")\n",
    "        y==1 ? println(\"was accepted\") : println(\"was not accepted\")\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict not accepted\n",
      "was accepted\n",
      "\n",
      "predict not accepted\n",
      "was accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict accepted\n",
      "was not accepted\n",
      "\n",
      "predict not accepted\n",
      "was accepted\n",
      "\n",
      "predict accepted\n",
      "was not accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict accepted\n",
      "was not accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was not accepted\n",
      "\n",
      "predict not accepted\n",
      "was not accepted\n",
      "\n",
      "predict accepted\n",
      "was accepted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i =1:length(x_data)\n",
    "    predict(x_data[i],y_data[i],w,b)\n",
    "    println(\"\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(x,y,w,b)\n",
    "    if σ(w'x+b) >= 0.5\n",
    "        return 1\n",
    "    else\n",
    "        return 0\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.275"
     ]
    }
   ],
   "source": [
    "mean_error = 0.0\n",
    "for i = 1:length(x_data)\n",
    "    mean_error += (predict(x_data[i], y_data[i], w, b) - y_data[i])^2\n",
    "end\n",
    "print(mean_error/length(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
